{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating a Personalized Music Recommendation Engine**\n",
        "\n",
        "**Project Goal:** Build a recommendation engine that learns user preferences and suggests songs based on past listening behavior using deep learning.\n",
        "\n",
        "**Skills Developed:** Collaborative filtering, building embeddings for recommendation, handling large-scale user-item interactions.\n"
      ],
      "metadata": {
        "id": "XfsH5WdumqB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Definition\n",
        "The goal of a music recommendation engine is to predict the songs that a user will most likely enjoy based on their past listening history and preferences. A common approach is to use collaborative filtering, which leverages patterns in the interactions between users and songs to make predictions.\n",
        "\n",
        "## Data Collection and Preprocessing\n",
        "Data Requirements: You need a dataset that contains information about users, songs, and interactions (e.g., play history, ratings, or likes).\n",
        "A popular dataset for this is Last.fm or Million Song Dataset.\n",
        "The dataset should include:\n",
        "\n",
        "> User IDs (unique identifier for each user)\n",
        "\n",
        "> Song IDs (unique identifier for each song)\n",
        "\n",
        "> Interaction data (e.g., ratings, number of plays, or time spent listening)\n"
      ],
      "metadata": {
        "id": "i5rvVNYalilE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Required Libraries\n",
        "\n",
        "Before starting the project, the necessary Python libraries must be imported. These include libraries for data manipulation, machine learning, and API handling."
      ],
      "metadata": {
        "id": "YvfxxtrVhJDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AqSFwmgYhIJt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: API Configuration\n",
        "\n",
        "Set up the API configuration to interact with Last.fm. This requires an API key and username, along with the base URL for API requests:\n",
        "\n",
        "**API_KEY:** The API key to authenticate requests.\n",
        "\n",
        "**USER:** The Last.fm username for fetching data. Here, we need to tell the user name that requires music recommendation\n",
        "\n",
        "**BASE_URL:** The base URL for Last.fm API endpoints."
      ],
      "metadata": {
        "id": "WdphBPg9iExD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"dfcd16d8f5058144250d9e2a9279fccd\"  # Replace with your Last.fm API key\n",
        "USER = \"the_atm\"  # Replace with your Last.fm username\n",
        "BASE_URL = \"http://ws.audioscrobbler.com/2.0/\"  # Base URL for Last.fm API"
      ],
      "metadata": {
        "id": "wm9V-fIbibXL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Fetch Data from Last.fm API\n",
        "\n",
        "Define a function, fetch_lastfm_data, to fetch the user's recent tracks from Last.fm using the API. The function sends a GET request to the user.getrecenttracks endpoint and retrieves the data in JSON format."
      ],
      "metadata": {
        "id": "dovj_4syiTpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_lastfm_data(user, api_key):\n",
        "    # Fetch the user's recent tracks\n",
        "    response = requests.get(BASE_URL, {\n",
        "        \"method\": \"user.getrecenttracks\",\n",
        "        \"user\": user,\n",
        "        \"api_key\": api_key,\n",
        "        \"format\": \"json\",\n",
        "        \"limit\": 1000  # Adjust limit as needed\n",
        "    })\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "# Call the API\n",
        "print(\"Fetching data from Last.fm...\")\n",
        "data = fetch_lastfm_data(USER, API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tom1hzKMikUb",
        "outputId": "5cd13571-9553-4526-b9d8-704c70f5d030"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from Last.fm...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Extract and Preprocess Data\n",
        "\n",
        "The data retrieved from the API is processed as follows:\n",
        "\n",
        "Extract the track information from the JSON response.\n",
        "\n",
        "Convert the extracted data into a pandas DataFrame with columns:\n",
        "\n",
        "**user_id:** Numeric ID assigned to the user.\n",
        "\n",
        "**song_name:** Name of the song.\n",
        "\n",
        "**artist_name:** Name of the artist.\n",
        "\n",
        "Encode the song and artist names into numeric IDs using LabelEncoder.\n",
        "\n",
        "Add an interaction column (interaction) to represent implicit user feedback (e.g., play count).\n",
        "\n",
        "Split the DataFrame into training and testing datasets using an 80-20 split."
      ],
      "metadata": {
        "id": "-goIzrkpiwhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse the JSON data into a DataFrame\n",
        "tracks = data['recenttracks']['track']\n",
        "df = pd.DataFrame([{\n",
        "    \"user_id\": 0,  # Assign numeric ID for the single user\n",
        "    \"song_name\": track['name'],\n",
        "    \"artist_name\": track['artist']['#text']\n",
        "} for track in tracks])\n",
        "\n",
        "print(\"Sample Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Encode song and artist names into numeric IDs\n",
        "df['song_id'] = LabelEncoder().fit_transform(df['song_name'])\n",
        "df['artist_id'] = LabelEncoder().fit_transform(df['artist_name'])\n",
        "\n",
        "# Add interaction column (e.g., play count or implicit rating)\n",
        "df['interaction'] = 1  # Treat all plays equally\n",
        "\n",
        "# Split into train and test sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx5jceXmi_tD",
        "outputId": "ad87d7cd-eb7e-4817-826d-b9fcdfd96643"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data:\n",
            "   user_id                song_name     artist_name\n",
            "0        0                       流杯     锦瑟​︱Brocade\n",
            "1        0                      小洞天     锦瑟​︱Brocade\n",
            "2        0  Atlantic (Instrumental)     Sleep Token\n",
            "3        0               The Keeper     Paul Ruskay\n",
            "4        0         Song of the Wood  Motoi Sakuraba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Build the Deep Learning Model\n",
        "\n",
        "**Model Architecture:**\n",
        "\n",
        "**Input Layers:** Separate inputs for user_id and song_id.\n",
        "\n",
        "\n",
        "**Embedding Layers:**\n",
        "\n",
        "**user_embedding:** Embedding for user IDs.\n",
        "\n",
        "**song_embedding:** Embedding for song IDs.\n",
        "\n",
        "**Concatenation:** Combine user and song embeddings.\n",
        "\n",
        "\n",
        "**Dense Layers:**\n",
        "\n",
        "A hidden layer with 128 neurons and ReLU activation.\n",
        "\n",
        "An output layer with 1 neuron and sigmoid activation.\n",
        "\n",
        "The model is compiled using the Adam optimizer and binary cross-entropy loss.\n",
        "\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "**num_users:** Total number of unique users (1 in this case).\n",
        "\n",
        "**num_songs:** Total number of unique songs.\n",
        "\n",
        "**embedding_dim:**Dimension of embedding space (set to 50)."
      ],
      "metadata": {
        "id": "qO7Sj6d9jHKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "num_users = 1  # Only one user (USER)\n",
        "num_songs = df['song_id'].nunique()\n",
        "embedding_dim = 50\n",
        "\n",
        "# Input layers\n",
        "user_input = tf.keras.layers.Input(shape=(1,))\n",
        "song_input = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "# Embedding layers\n",
        "user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)(user_input)\n",
        "song_embedding = tf.keras.layers.Embedding(num_songs, embedding_dim)(song_input)\n",
        "\n",
        "# Flatten embeddings\n",
        "user_vec = tf.keras.layers.Flatten()(user_embedding)\n",
        "song_vec = tf.keras.layers.Flatten()(song_embedding)\n",
        "\n",
        "# Concatenate embeddings\n",
        "concat = tf.keras.layers.Concatenate()([user_vec, song_vec])\n",
        "dense = tf.keras.layers.Dense(128, activation='relu')(concat)\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "# Create model\n",
        "model = tf.keras.Model(inputs=[user_input, song_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "yUmq16kpjhJ7",
        "outputId": "a8ee60b3-75c2-4529-f96f-10982590489d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │             \u001b[38;5;34m50\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │         \u001b[38;5;34m40,400\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m12,928\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,507\u001b[0m (209.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,507</span> (209.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m53,507\u001b[0m (209.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,507</span> (209.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Train the Model\n",
        "\n",
        "**Prepare the input data for training and testing:**\n",
        "\n",
        "**X_train:** Input data for training (user and song IDs).\n",
        "\n",
        "**y_train:** Interaction data for training.\n",
        "\n",
        "**X_test:** Input data for testing.\n",
        "\n",
        "**y_test:** Interaction data for testing.\n",
        "\n",
        "Train the model using the fit method with 10 epochs and a batch size of 32. Validate the model on the test dataset during training."
      ],
      "metadata": {
        "id": "dsrs9GAfjg6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input data\n",
        "X_train = [train['user_id'], train['song_id']]\n",
        "y_train = train['interaction']\n",
        "\n",
        "X_test = [test['user_id'], test['song_id']]\n",
        "y_test = test['interaction']\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MSDguhkjzzz",
        "outputId": "9139e918-38ec-4a29-dd85-2b54c7a16bde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8220 - loss: 0.6000 - val_accuracy: 1.0000 - val_loss: 0.1895\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.1016 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4648e-04 - val_accuracy: 1.0000 - val_loss: 8.0391e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0223e-04 - val_accuracy: 1.0000 - val_loss: 6.1973e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4456e-04 - val_accuracy: 1.0000 - val_loss: 4.9089e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3367e-04 - val_accuracy: 1.0000 - val_loss: 3.9756e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5254e-04 - val_accuracy: 1.0000 - val_loss: 3.2799e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9205e-04 - val_accuracy: 1.0000 - val_loss: 2.7484e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Evaluate the Model\n",
        "\n",
        "Evaluate the model's performance using the evaluate method on the test dataset. The output includes:\n",
        "\n",
        "> Test Loss\n",
        "\n",
        "> Test Accuracy"
      ],
      "metadata": {
        "id": "0aTb4c4cjzaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFMJq6wlkKnk",
        "outputId": "d9c42100-0803-49b8-ce5e-e2465343316a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7444e-04 \n",
            "Test Loss: 0.00027484106249175966, Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Test Recommendations for a User\n",
        "\n",
        "Define a function, recommend_songs, to generate song recommendations for the user:\n",
        "\n",
        "\n",
        "> Create an array of user IDs (user_array) and song IDs (song_array).\n",
        "\n",
        "> Use the trained model to predict interaction scores for all songs.\n",
        "\n",
        "> Identify the top 5 songs with the highest predicted scores.\n",
        "\n",
        "> Retrieve and display the names and artists of the recommended songs."
      ],
      "metadata": {
        "id": "ooPTWqj5kQvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate song recommendations\n",
        "def recommend_songs(num_recommendations=5):\n",
        "    user_array = np.array([0] * num_songs)  # Single user\n",
        "    song_array = np.array(range(num_songs))\n",
        "\n",
        "    predictions = model.predict([user_array, song_array])\n",
        "    recommended_songs = predictions.flatten().argsort()[-num_recommendations:][::-1]\n",
        "\n",
        "    recommended_df = df[df['song_id'].isin(recommended_songs)]\n",
        "    print(\"\\nRecommended Songs:\")\n",
        "    print(recommended_df[['song_name', 'artist_name']].drop_duplicates())\n",
        "    return recommended_df[['song_name', 'artist_name']].drop_duplicates()\n",
        "\n",
        "# Get recommendations\n",
        "recommendations = recommend_songs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVAEz2edkd6j",
        "outputId": "6a1f1f3b-5763-4ea8-e4a6-442235f8b4c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\n",
            "Recommended Songs:\n",
            "                       song_name          artist_name\n",
            "37                      Whiplash           Architects\n",
            "105          The Light in Us Now           J.J. Ipsen\n",
            "146  It’s All So Incredibly Loud        Glass Animals\n",
            "321                   Soft Spine            Spiritbox\n",
            "603           Edge of the Sundom  Niels van der Leest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working\n",
        "\n",
        "The system suggests songs based on the patterns it finds in your listening habits. Here's how it works in simple terms:\n",
        "\n",
        "The system looks at:\n",
        "\n",
        "Songs You’ve Listened To: It tracks which songs you have played recently.\n",
        "\n",
        "Artists You Like: It also keeps track of the artists whose songs you listen to the most.\n",
        "\n",
        "The system then treats each song and artist as a unique item. It learns which songs you enjoy by connecting the songs you’ve listened to with the artists you like. It remembers these connections and uses them to suggest other songs that are similar in style or by artists you might also enjoy.\n",
        "\n",
        "So, when you ask for song recommendations, the system uses the patterns it learned from your past listening habits—what songs you liked and who the artists are—to suggest new songs you might like in the future. It’s like a friend recommending songs they think you’ll love based on what they know you’ve enjoyed before.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A3xwPX2NoyXY"
      }
    }
  ]
}